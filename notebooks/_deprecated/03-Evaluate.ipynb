{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ea9b39-afaa-4d27-b1bb-733b6accbe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from constants import EVALUATION_DATE_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f309c9-1d1d-4f09-b6ae-a277bf7bf994",
   "metadata": {},
   "source": [
    "# Evaluate (Deprecated!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729be2b3-3f27-44d2-8074-424a7edd3ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a WAVE API key stored in a local file\n",
    "with open('../input/api.lab.key', 'r') as f:\n",
    "    API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcb0dd0",
   "metadata": {},
   "source": [
    "## Data Portals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45394641",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get filtered resources' page URLs and page IDs\n",
    "\"\"\"\n",
    "df_pages = pd.read_csv(os.path.join('..', 'output', EVALUATION_DATE_FOLDER, 'data-portal_pages.csv'))\n",
    "df_map = pd.read_csv(os.path.join('..', 'output', 'data-portal_id_map.csv'))\n",
    "\n",
    "# Get ids to filter by. Let's just look at the manually collected ones for now.\n",
    "df_filtered = pd.read_csv(os.path.join('..', 'output', EVALUATION_DATE_FOLDER, 'data-portal_filtered_ids.csv'))\n",
    "FILTER_IDS = list(set(df_filtered.id.values.tolist()))\n",
    "\n",
    "# Filter pages by selected IDs. Also, empty URLs are excluded.\n",
    "df_pages = df_pages[(df_pages.id.isin(FILTER_IDS)) & (~df_pages.url.isnull())]\n",
    "\n",
    "# df_pages = df_pages.head(1) # for debuging purposes\n",
    "df_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecf8b75-efb2-427c-88f2-e3f93f3037b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Collect raw reports all together first using API calls\n",
    "\"\"\"\n",
    "def collect_raw_reports_and_save(df_pages, RAW_REPORTS_FOLDER):    \n",
    "    # Create a folder to store raw reports, if missing\n",
    "    Path(RAW_REPORTS_FOLDER).mkdir(exist_ok=True)\n",
    "\n",
    "    \"\"\" \n",
    "    Collect missing reports one by one, and save them as a file\n",
    "    \"\"\"\n",
    "    for _, row in df_pages.iterrows():\n",
    "        page_id = row.page_id\n",
    "        url = row.url\n",
    "\n",
    "        # Skip if the report already exists\n",
    "        PAGE_REPORT_PATH = os.path.join(RAW_REPORTS_FOLDER, f'{page_id}.json')\n",
    "        is_exist = os.path.isfile(PAGE_REPORT_PATH)\n",
    "\n",
    "        if is_exist:\n",
    "            print(f'Report for {url} already exists. Skipping ...')\n",
    "            continue\n",
    "        else:\n",
    "            # Twick...\n",
    "            if int(page_id.split('_')[0]) < 27955:\n",
    "                PAGE_REPORT_PATH = os.path.join(RAW_REPORTS_FOLDER, f'{int(page_id.split(\"_\")[0]) + 27955}_{page_id.split(\"_\")[1]}.json')\n",
    "                if os.path.isfile(PAGE_REPORT_PATH):\n",
    "                    continue\n",
    "        \n",
    "        # Refer to https://wave.webaim.org/api/docs#!/request/getRequest for the API documentation\n",
    "        API_URL = f'https://wave.webaim.org/api/request?key={API_KEY}&reporttype=2&url={url}'\n",
    "        \n",
    "        print(f'Retrieving {url} ...')\n",
    "\n",
    "        try:\n",
    "            with urllib.request.urlopen(API_URL) as f:\n",
    "                new_report = json.load(f) # Refer to `../output/raw-reports-examples` to understand the structure of the report\n",
    "\n",
    "                # Save the raw report\n",
    "                with open(PAGE_REPORT_PATH, 'w') as f:\n",
    "                    json.dump(new_report, f)\n",
    "        except:\n",
    "            print('Failed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed13c0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_REPORTS_FOLDER = os.path.join('..', 'output', EVALUATION_DATE_FOLDER, 'raw-reports', 'data-portal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6149c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_raw_reports_and_save(\n",
    "    df_pages,\n",
    "    RAW_REPORTS_FOLDER\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbbda7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_from_raw_reports(df_pages, RAW_REPORTS_FOLDER):\n",
    "    # Assumption in this function is that the raw reports are already collected\n",
    "\n",
    "    # All reports to be saved as a dataframe\n",
    "    reports = []\n",
    "    for _, row in df_pages.iterrows():\n",
    "        # The dictionary to be saved as a row in the dataframe\n",
    "        cleaned_report = {}\n",
    "\n",
    "        # The primary key column we use to identify each page\n",
    "        page_id = row.page_id\n",
    "        \n",
    "        PAGE_REPORT_PATH = os.path.join(RAW_REPORTS_FOLDER, f'{page_id}.json')\n",
    "\n",
    "        if not os.path.isfile(PAGE_REPORT_PATH):\n",
    "            # Twick...\n",
    "            if int(page_id.split('_')[0]) < 27955:\n",
    "                PAGE_REPORT_PATH = os.path.join(RAW_REPORTS_FOLDER, f'{int(page_id.split(\"_\")[0]) + 27955}_{page_id.split(\"_\")[1]}.json')\n",
    "                if not os.path.isfile(PAGE_REPORT_PATH):\n",
    "                    print(f'Odd. Report for {page_id} does not exist. Skipping ...')\n",
    "                    continue\n",
    "\n",
    "        with open(PAGE_REPORT_PATH, 'r') as f:\n",
    "            page_report = json.load(f)\n",
    "\n",
    "        is_success = page_report.get('status').get('success')\n",
    "\n",
    "        # Add basic information\n",
    "        cleaned_report |= { \n",
    "            'page_id': page_id,\n",
    "            'is_success': is_success\n",
    "        }\n",
    "\n",
    "\n",
    "        if is_success == True:\n",
    "            error_items = page_report.get('categories').get('error').get('items')\n",
    "            alert_items = page_report.get('categories').get('alert').get('items')\n",
    "            contrast_items = page_report.get('categories').get('contrast').get('items')\n",
    "        \n",
    "            error_count = page_report.get('categories').get('error').get('count')\n",
    "            alert_count = page_report.get('categories').get('alert').get('count')\n",
    "            contrast_count = page_report.get('categories').get('contrast').get('count')\n",
    "            \n",
    "            cleaned_report |= { \n",
    "                'count': error_count + alert_count + contrast_count,\n",
    "                'category_count': len(error_items) + len(alert_items) + len(contrast_items),\n",
    "                'error_count': error_count,\n",
    "                'alert_count': alert_count,\n",
    "                'contrast_count': contrast_count,\n",
    "            }\n",
    "\n",
    "            # Example: \n",
    "            # {\n",
    "            #   'label_missing': {'id': 'label_missing', 'description': 'Missing form label', 'count': 1}, \n",
    "            #   'language_missing': {'id': 'language_missing', 'description': 'Language missing or invalid', 'count': 1}, \n",
    "            #   'button_empty': {'id': 'button_empty', 'description': 'Empty button', 'count': 1}\n",
    "            # }\n",
    "\n",
    "            if len(error_items) != 0:\n",
    "                for item in error_items.values():\n",
    "                    cleaned_report |= { f\"error_{item.get('id')}\": item.get('count') }\n",
    "            if len(alert_items) != 0:\n",
    "                for item in alert_items.values():\n",
    "                    cleaned_report |= { f\"alert_{item.get('id')}\": item.get('count') }\n",
    "            if len(contrast_items) != 0:\n",
    "                for item in contrast_items.values():\n",
    "                    cleaned_report |= { f\"contrast_{item.get('id')}\": item.get('count') }\n",
    "            \n",
    "            reports.append(cleaned_report)\n",
    "\n",
    "    return pd.DataFrame.from_records(reports)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff01244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reports = create_dataframe_from_raw_reports(df_pages, RAW_REPORTS_FOLDER)\n",
    "df_reports.to_csv(os.path.join('..', 'output', EVALUATION_DATE_FOLDER, 'data-portal_evaluation.csv'), index=False)\n",
    "df_reports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875345fa",
   "metadata": {},
   "source": [
    "## Journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb68f3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get filtered resources' page URLs and page IDs\n",
    "\"\"\"\n",
    "df_pages = pd.read_csv(os.path.join('..', 'output', EVALUATION_DATE_FOLDER, 'journal-portal_pages.csv'))\n",
    "df_map = pd.read_csv(os.path.join('..', 'output', 'journal-portal_id_map.csv'))\n",
    "\n",
    "# Get ids to filter by. Let's just look at the manually collected ones for now.\n",
    "# TODO: use the filtered data from `02-Filter.ipynb`!\n",
    "df_filtered = pd.read_csv(os.path.join('..', 'output', EVALUATION_DATE_FOLDER, 'journal-portal_filtered_ids.csv'))\n",
    "FILTER_IDS = list(set(df_filtered.id.values.tolist()))\n",
    "\n",
    "# Filter pages by selected IDs. Also, empty URLs are excluded.\n",
    "df_pages = df_pages[(df_pages.id.isin(FILTER_IDS)) & (~df_pages.url.isnull())]\n",
    "\n",
    "# df_pages = df_pages.head(1) # for debuging purposes\n",
    "df_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b435420",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_REPORTS_FOLDER = os.path.join('..', 'output', EVALUATION_DATE_FOLDER, 'raw-reports', 'journal-portal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df449672",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_raw_reports_and_save(\n",
    "    df_pages,\n",
    "    RAW_REPORTS_FOLDER\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b420c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reports = create_dataframe_from_raw_reports(df_pages, RAW_REPORTS_FOLDER)\n",
    "df_reports.to_csv(os.path.join('..', 'output', EVALUATION_DATE_FOLDER, 'journal-portal_evaluation.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581a940c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
